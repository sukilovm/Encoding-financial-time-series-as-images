{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Running this notebook consumes multiple hours and excessive RAM. <br> As a result, file references and function calls are commented out.\n",
        "<br> <br>\n",
        "The code is provided for clarity and understanding.** <br>"
      ],
      "metadata": {
        "id": "0VBjRmArtjxx"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIRWAi7JcUgE"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZ6LLpKXE6m9",
        "outputId": "b733a835-5e46-41af-c868-0e759fbab51b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fp4YXTshuUeT"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install mplfinance\n",
        "!pip install opencv-python-headless\n",
        "!pip install pyts\n",
        "!pip install tqdm\n",
        "import pickle\n",
        "import mplfinance as mpf\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from io import BytesIO\n",
        "from pyts.image import MarkovTransitionField\n",
        "from pyts.image import GramianAngularField\n",
        "from pyts.image import RecurrencePlot\n",
        "from scipy.signal import spectrogram\n",
        "import pywt\n",
        "import gc\n",
        "import time\n",
        "from skimage.measure import block_reduce\n",
        "from tqdm import tqdm\n",
        "\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", message=\"Some quantiles are equal.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0yDH2Qtcdzz"
      },
      "source": [
        "## Load Time Series (RAW)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code segment loads the time series windows and labels generated in the previous notebook **Thesis_Data**."
      ],
      "metadata": {
        "id": "4FwNJJZ_rDgg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQpyJA23FIkP"
      },
      "outputs": [],
      "source": [
        "# Define the file path\n",
        "# file_path = \"/content/drive/MyDrive/20230424_windows_and_labels.pkl\"\n",
        "\n",
        "# Load the variables\n",
        "# with open(file_path, 'rb') as f:\n",
        "#    windows, labels, max_years = pickle.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_c7n9iPicfWH"
      },
      "source": [
        "## Encode Time Series (RAW) as Images"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code segments use the previously loaded time series data and encode them as images, <br>  applying the CND, MTF and GAF methods defined in the thesis paper."
      ],
      "metadata": {
        "id": "O-rXEq23pjG5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Candlestick Charts (CND)"
      ],
      "metadata": {
        "id": "rCIPXOj8kcF4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Used to visualize image encodigs\n",
        "def display_arrays(arrays):\n",
        "    for i, array in enumerate(arrays):\n",
        "        cv2_imshow(array)\n",
        "\n",
        "        # Add a separator line between images\n",
        "        print('\\n' + '-' * 15 + '\\n')"
      ],
      "metadata": {
        "id": "gb5xG6BD2Kh0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_greyscale_conversion(img):\n",
        "    red_channel = img[:, :, 2]\n",
        "    green_channel = img[:, :, 1]\n",
        "    blue_channel = img[:, :, 0]\n",
        "\n",
        "    # Convert the image to greyscale using OpenCV's built-in function\n",
        "    grey_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Create masks to extract red and green candles\n",
        "    red_mask = (red_channel > green_channel) & (blue_channel < red_channel)\n",
        "    green_mask = (green_channel > red_channel) & (blue_channel < green_channel)\n",
        "\n",
        "    # Create a custom greyscale image by emphasizing the difference between red and green channels\n",
        "    custom_grey_img = grey_img.copy()\n",
        "    custom_grey_img[red_mask] = grey_img[red_mask] * 1.5\n",
        "    custom_grey_img[green_mask] = grey_img[green_mask] * 0.5\n",
        "\n",
        "    # Clip the custom greyscale image to the range [0, 255]\n",
        "    custom_grey_img = np.clip(custom_grey_img, 0, 255)\n",
        "\n",
        "    return custom_grey_img.astype(np.uint8)\n",
        "\n",
        "def max_pooling(img, pool_size):\n",
        "    return block_reduce(img, block_size=(pool_size, pool_size), func=np.max)\n",
        "\n",
        "def generate_candlestick_array(window):\n",
        "    target_size = (20, 20)\n",
        "    pool_size = 2\n",
        "\n",
        "    num_rows = window.shape[0]\n",
        "    temp_index = pd.date_range(start='2000-01-01', periods=num_rows, freq='D')\n",
        "    temp_window = window.copy()\n",
        "    temp_window.index = temp_index\n",
        "\n",
        "    fig, ax = mpf.plot(temp_window, type='candle', style='charles', returnfig=True, axisoff=True)\n",
        "\n",
        "    buf = BytesIO()\n",
        "    fig.savefig(buf, format='png', bbox_inches='tight')\n",
        "    plt.close(fig)\n",
        "\n",
        "    buf.seek(0)\n",
        "    img = cv2.imdecode(np.frombuffer(buf.read(), np.uint8), -1)\n",
        "\n",
        "    grey_img = custom_greyscale_conversion(img)\n",
        "\n",
        "    pooled_grey_img = max_pooling(grey_img, pool_size)\n",
        "\n",
        "    resized_grey_img = cv2.resize(pooled_grey_img, target_size, interpolation=cv2.INTER_AREA)\n",
        "\n",
        "    return resized_grey_img"
      ],
      "metadata": {
        "id": "yLBqzXmU-fXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For Candlestick image generation\n",
        "def split_list(lst, chunk_size):\n",
        "    return [lst[i:i + chunk_size] for i in range(0, len(lst), chunk_size)]\n",
        "\n",
        "chunk_size = 30000\n",
        "\n",
        "# windows_chunks = split_list(windows, chunk_size)\n",
        "# labels_chunks = split_list(labels, chunk_size)\n",
        "# max_years_chunks = split_list(max_years, chunk_size)"
      ],
      "metadata": {
        "id": "obUmY2nb2Bsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "candlestick_arrays_chunk_8 = []\n",
        "\n",
        "for window in tqdm(windows_chunks[7], desc=\"Processing windows\"):\n",
        "    candlestick_array = generate_candlestick_array(window)\n",
        "    candlestick_arrays_chunk_8.append(candlestick_array)\n",
        "    del candlestick_array\n",
        "\n",
        "## Upload arrays to Google Drive\n",
        "\n",
        "# Define the file path\n",
        "# file_path = \"/content/drive/MyDrive/20230425_candlestick_arrays_chunk_8.pkl\"\n",
        "\n",
        "# with open(file_path, 'wb') as f:\n",
        "#   pickle.dump((candlestick_arrays_chunk_8), f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odK9YDF63V74",
        "outputId": "24d23452-535d-4db3-d0ee-c6026ace1564"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing windows: 100%|██████████| 28678/28678 [2:25:21<00:00,  3.29it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Markov Transition Fields (MTF)"
      ],
      "metadata": {
        "id": "PR5fXBoQkhGt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_mtf_arrays(windows, n_bins=5, size=(20, 20)):\n",
        "    images = []\n",
        "    mtf = MarkovTransitionField(n_bins=n_bins)\n",
        "\n",
        "    for window in windows:\n",
        "        # Extract the 'Close' column from the window\n",
        "        close_prices = window['Close'].values\n",
        "\n",
        "        # Compute the MTF\n",
        "        mtf_image = mtf.fit_transform([close_prices])[0]\n",
        "\n",
        "        # Normalize the MTF image to the range [0, 1]\n",
        "        mtf_image_normalized = (mtf_image - mtf_image.min()) / (mtf_image.max() - mtf_image.min())\n",
        "\n",
        "        # Convert the normalized MTF image to a grayscale image\n",
        "        mtf_image_grayscale = (mtf_image_normalized * 255).astype(np.uint8)\n",
        "\n",
        "        # Resize the MTF image\n",
        "        mtf_image_resized = cv2.resize(mtf_image_grayscale, size, interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "        # Append the image to the list of images\n",
        "        images.append(mtf_image_resized)\n",
        "\n",
        "    return images\n",
        "\n",
        "# mtf_arrays = generate_mtf_arrays(windows)\n",
        "\n",
        "## Upload arrays to Google Drive\n",
        "\n",
        "# Define the file path\n",
        "# file_path = \"/content/drive/MyDrive/20230425_mtf_arrays.pkl\"\n",
        "\n",
        "# with open(file_path, 'wb') as f:\n",
        "#   pickle.dump((mtf_arrays), f)\n",
        "\n",
        "# display_arrays(mtf_arrays)"
      ],
      "metadata": {
        "id": "XxYX84K8UnXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gramian Angular Fields (GAF)"
      ],
      "metadata": {
        "id": "5phIl-VQkltn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_gaf_difference_arrays(windows, method='difference', size=(20, 20)):\n",
        "    arrays = []\n",
        "    gaf = GramianAngularField(method=method)\n",
        "\n",
        "    for window in windows:\n",
        "        close_prices = window['Close'].values\n",
        "        gaf_image = gaf.fit_transform([close_prices])[0]\n",
        "        gaf_image_normalized = (gaf_image - gaf_image.min()) / (gaf_image.max() - gaf_image.min())\n",
        "\n",
        "        # Convert the normalized GAF image to a greyscale image\n",
        "        gaf_image_grayscale = (gaf_image_normalized * 255).astype(np.uint8)\n",
        "\n",
        "        # Resize the greyscale GAF image\n",
        "        gaf_image_resized = cv2.resize(gaf_image_grayscale, size, interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "        arrays.append(gaf_image_resized)  # Append the resized greyscale array to the list of arrays\n",
        "\n",
        "    return arrays\n",
        "\n",
        "# gaf_arrays = generate_gaf_difference_arrays(windows)\n",
        "\n",
        "## Upload arrays to Google Drive\n",
        "\n",
        "# Define the file path\n",
        "# file_path = \"/content/drive/MyDrive/20230425_gaf_arrays.pkl\"\n",
        "\n",
        "# with open(file_path, 'wb') as f:\n",
        "#   pickle.dump((gaf_arrays), f)\n",
        "\n",
        "# display_arrays(gaf_arrays)"
      ],
      "metadata": {
        "id": "dPd1nlVqm_zf"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "toc_visible": true,
      "gpuClass": "premium"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}